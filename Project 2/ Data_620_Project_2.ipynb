{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMT1jEQeGR+Vjj1MzkuIiA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lfirenzeg/msds620/blob/main/Project%202/%20Data_620_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCeySJiIyPJa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data 620\n",
        "# Project 2\n",
        "\n",
        "### By Luis Munoz Grass\n",
        "\n",
        "1. Identify a large 2-node network dataset—you can start with a dataset in a repository.  Your data should meet the criteria that it consists of ties between and not within two (or more) distinct groups.\n",
        "\n",
        "2. Reduce the size of the network using a method such as the island method described in chapter 4 of social network analysis.\n",
        "\n",
        "3. What can you infer about each of the distinct groups?"
      ],
      "metadata": {
        "id": "4E1eQR_ryQrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n"
      ],
      "metadata": {
        "id": "2h5pNFK2yi7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip -q ml-1m.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhwkYGtp3EXj",
        "outputId": "12edc821-efa2-44b7-8197-689e21fb3e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-30 03:35:43--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  9.69MB/s    in 0.6s    \n",
            "\n",
            "2025-06-30 03:35:44 (9.69 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before building any graph, we need to make sure the raw data has loaded correctly and to understand its basic dimensions."
      ],
      "metadata": {
        "id": "_CWmUTfQ60Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "ratings = pd.read_csv(\n",
        "    'ml-1m/ratings.dat',\n",
        "    sep='::',\n",
        "    engine='python',\n",
        "    names=['user','item','rating','ts']\n",
        ")\n",
        "\n",
        "print(\"Ratings shape:\", ratings.shape)\n",
        "print(ratings.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq3MWYL93Gi7",
        "outputId": "95156986-0973-4368-b755-3b5605376a51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings shape: (1000209, 4)\n",
            "   user  item  rating         ts\n",
            "0     1  1193       5  978300760\n",
            "1     1   661       3  978302109\n",
            "2     1   914       3  978301968\n",
            "3     1  3408       4  978300275\n",
            "4     1  2355       5  978824291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 1'000.209 rating events, each with a user ID, an item (movie) ID, a rating in (1…5), and a timestamp.\n",
        "\n",
        "The first few rows look as expected, confirming the double colon parsing worked fine."
      ],
      "metadata": {
        "id": "jrc4l6r5635h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " We'll now represent users and movies as two disjoint node sets, and each rating as a weighted edge. This structure should let us analyze cross mode interactions directly."
      ],
      "metadata": {
        "id": "Z-cdMwHX7DHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B = nx.Graph()\n",
        "B.add_nodes_from(ratings['user'].unique(), bipartite='users')\n",
        "B.add_nodes_from(ratings['item'].unique(), bipartite='movies')\n",
        "\n",
        "\n",
        "edges = ratings[['user','item','rating']].itertuples(index=False, name=None)\n",
        "B.add_weighted_edges_from(edges)\n",
        "\n",
        "print(\"Original graph:\", B.number_of_nodes(), \"nodes,\", B.number_of_edges(), \"edges\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTkcKup63IzF",
        "outputId": "10506299-c172-475e-c114-9cffd0f23822"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original graph: 6040 nodes, 987317 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now find the graph contains 6040 distinct nodes (the sum of unique users and movies) and 987.317 edges.\n",
        "\n",
        "In this case an edge count close to the number of ratings means almost every rating became its own edge, showing very little deduplication.\n",
        "\n",
        "Also, we can see that a high edge to node ratio (at least 163 edges per node) indicate a dense network since many users have rated many movies."
      ],
      "metadata": {
        "id": "aBxKGGTl7I-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Reducing the Size of the Network\n",
        "\n",
        " We'll assune we are only interested in \"strong\" preferences, so ratings of 4 or 5. When we remove weaker ties and then drop any isolated nodes, we can focus on the core subnetwork of \"most meaningful\" user movie relationships."
      ],
      "metadata": {
        "id": "2R-4XDl_7ZBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 4.0\n",
        "to_keep = [(u,v,d) for u,v,d in B.edges(data=True) if d['weight'] >= threshold]\n",
        "B_core = nx.Graph()\n",
        "B_core.add_edges_from([(u,v,{'weight':w}) for u,v,w in ((u,v,d['weight']) for u,v,d in to_keep)])\n",
        "# drop isolates\n",
        "B_core.remove_nodes_from(list(nx.isolates(B_core)))\n",
        "\n",
        "print(\"Pruned core:\", B_core.number_of_nodes(), \"nodes,\", B_core.number_of_edges(), \"edges\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUKathcX3KdI",
        "outputId": "ae6ebf4c-7ccf-4131-e6f9-95d563fcf155"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned core: 6039 nodes, 567942 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "419.375 edges (those with ratings < 4) were pruned, so about 42% of the original edges.\n",
        "\n",
        "Interestingly, only one node became completely isolated and was removed (from 6040 to 6039 nodes), showing almost everyone retained at least one strong tie.\n",
        "\n",
        "The remaining 567.942 edges represent the subset of users and movies connected by mostly positive feedback.\n",
        "\n",
        "But what if we want to find \"power users\"? Let's see first the top 10 people with most ratings."
      ],
      "metadata": {
        "id": "0rCP5gR07vIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many ratings above 4 each user made\n",
        "strong_counts = (\n",
        "    ratings[ratings.rating >= 4]\n",
        "    .groupby('user')\n",
        "    .size()\n",
        "    .sort_values(ascending=False)\n",
        ")\n",
        "\n",
        "top10 = strong_counts.head(10)\n",
        "print(top10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FVz72KO9E9w",
        "outputId": "b9720b4a-8f90-4b77-ac55-b495e17d8ca6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user\n",
            "4277    1435\n",
            "4169    1210\n",
            "1680    1108\n",
            "3032     861\n",
            "5831     826\n",
            "3539     819\n",
            "2909     817\n",
            "4448     814\n",
            "1285     800\n",
            "1015     794\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top 10 users are exceptionally active!\n",
        "User 4277 has given 1435 ratings of 4 or 5, and even the 10th most intense (user 1015) has 794 strong ratings.\n",
        "This small group of about ten users alone accounts for over 8000 high quality feedbacks.\n",
        "So let's see how many users have rated over 100 movies:"
      ],
      "metadata": {
        "id": "TLhbLGhn9Qq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_counts = ratings.groupby('user').size()\n",
        "\n",
        "# filter for users with more than 100 ratings\n",
        "users_over100 = total_counts[total_counts > 100]\n",
        "\n",
        "num_users_over100 = users_over100.shape[0]\n",
        "print(f\"Number of users who rated over 100 movies: {num_users_over100}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbrGj9Ax9gMe",
        "outputId": "02d38963-d93b-4bfe-edeb-a5e89ee5f5a2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users who rated over 100 movies: 2909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "About 2909 users rated more than 100 movies. And that's nearly 48% of the entire user base (6040 users). This tells us that almost half of all users are highly engaged, contributing a large volume of ratings, while the remaining half are more casual raters."
      ],
      "metadata": {
        "id": "VvQseObY98Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Observations\n",
        "\n",
        "### Users\n",
        "\n",
        "Almost all stayed in the core we were looking. Surprisingly only one node dropped out, meaning that virtually every user in the almost 1M ratings dataset gave at least one \"strong\" rating (bigger than 4). We can also say everyone who sampled the data still had something they really liked.\n",
        "\n",
        "Activity is skewed, as we found, there was a small set of \"power raters\" who account for a large chunk of the high ratings. These are your super engaged listeners.\n",
        "\n",
        "### Movies\n",
        "\n",
        "A relatively small number of movies rack up huge numbers of high ratings and form the backbone of the core. These would be  all time favorites, classics, recent hits, franchise entries, etc.\n",
        "\n",
        "Movies with fewer total ratings can still appear if those ratings are overwhelmingly positive. These are more likely to be cult favorites (notsuper  popular but with very passionate followings).\n",
        "\n",
        "Even after pruning, there's a long tail of movies with just a handful of strong ratings. Their presence tells us that the algorithmic \"island\" still captures real diversity in users tastes.\n",
        "\n"
      ],
      "metadata": {
        "id": "gW5DO74T8Cun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source\n",
        "B. Rozemberczki and R. Sarkar. Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models. 2020"
      ],
      "metadata": {
        "id": "Rw1oN5s3zWIy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xvxTZ8A1zcjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}